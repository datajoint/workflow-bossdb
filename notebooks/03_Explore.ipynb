{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataJoint U24 - Workflow Volume\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Interactively run the workflow\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you haven't configured your set up, refer to [01-Configure](./01-Configure.ipynb).\n",
    "- For an overview of the schema, refer to [02-WorkflowStructure](02-WorkflowStructure_Optional.ipynb).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the directory to load the local config, `dj_local_conf.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pipeline.py` activates the various schema and declares other required tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting cbroz@dss-db.datajoint.io:3306\n"
     ]
    }
   ],
   "source": [
    "import datajoint as dj\n",
    "from datetime import datetime\n",
    "from workflow_volume.pipeline import (\n",
    "    lab,\n",
    "    subject,\n",
    "    session,\n",
    "    volume,\n",
    "    bossdb,\n",
    "    get_session_directory,\n",
    "    get_vol_root_data_dir,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Manually Inserting Entries\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upstream tables\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can insert entries into `dj.Manual` tables (green in diagrams) by providing values as a dictionary or a list of dictionaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# \n",
       "subject              : varchar(32)                  # \n",
       "session_datetime     : datetime(3)                  # "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subject.Subject.insert1(\n",
    "    dict(subject=\"sub1\", sex=\"M\", subject_birth_date=datetime.now()),\n",
    "    skip_duplicates=True,\n",
    ")\n",
    "session_key = (subject.Subject & \"subject='sub1'\").fetch1(\"KEY\")\n",
    "session.Session.insert1(\n",
    "    dict(\n",
    "        **session_key,\n",
    "        session_id=1,\n",
    "        session_datetime=datetime.now(),\n",
    "    ),\n",
    "    skip_duplicates=True,\n",
    ")\n",
    "session.SessionDirectory.insert1(\n",
    "    dict(**session.Session.fetch1(\"KEY\"), session_dir=\"<your-data-path>\"),\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_session_directory` will fetch your relative directory path form this `SessionDirectory` table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from element_interface.utils import find_full_path\n",
    "\n",
    "data_path = find_full_path(get_vol_root_data_dir(), get_session_directory(session_key))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Element Volume Tables\n",
    "\n",
    "#### Uploading\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Resolution` table keeps track details related to data collection, including units and size in each dimension. `downsampling` indicates number of times the dataset has been compressed by taking every other pixel. Within BossDB, resolution 3 data (here, `downsampling` 3) reflects every 8th pixel, for example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume.Resolution.insert1(\n",
    "    dict(\n",
    "        resolution_id=\"990nm\",\n",
    "        voxel_unit=\"micrometers\",\n",
    "        voxel_z_size=1,\n",
    "        voxel_y_size=0.5,\n",
    "        voxel_x_size=0.5,\n",
    "        downsampling=0,\n",
    "    ),\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BossDB operates with a hierarchy of collections, experiments, and channels. A collection spans multiple experiments. An experiment may collect one or more channels, including electron micrioscopy data, segmentation annotations, and connectome data. These form the portions of a BossDB URL.\n",
    "\n",
    "Here, we choose some example values. With the proper permissions, we can create a BossDB dataset right from our Python environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection, experiment, volume, segmentation = (\n",
    "    \"DataJointTest\",\n",
    "    \"test\",\n",
    "    \"CalciumImaging\",\n",
    "    \"Segmented\",\n",
    ")\n",
    "\n",
    "bossdb.BossDBURLs.load_bossdb_info(\n",
    "    collection=collection,\n",
    "    experiment=experiment,\n",
    "    volume=volume,\n",
    "    segmentation=segmentation,\n",
    "    skip_duplicates=True,\n",
    ")\n",
    "url_key = (\n",
    "    bossdb.BossDBURLs.Volume & dict(collection_experiment=f\"{collection}/{experiment}\")\n",
    ").fetch1()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_sample_data` function below provides a template for loading a multi-page tif file and saving it into individual Z-axis images.\n",
    "\n",
    "In the next step, we can choose to upload to BossDB either with individual images in a directory or through an image volume in memory. To store the volume data in the table, replace the contents below with a function that loads your data.\n",
    "\n",
    "Note: BossDB only accepts image data as `uint8` or `uint16` numpy arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data():\n",
    "    from tifffile import TiffFile\n",
    "    from PIL import Image\n",
    "    from pathlib import Path\n",
    "\n",
    "    root_dir = get_vol_root_data_dir()[0]\n",
    "    image_fp = root_dir + \"<your-data-path>/<your-file-name>.tif\"\n",
    "    png_fp = root_dir + \"sample/Z%02d.png\"  # Z-plane\n",
    "    image_sample = TiffFile(image_fp).asarray()\n",
    "\n",
    "    image_sample = image_sample.astype(\"uint16\")\n",
    "    if not Path(png_fp % 0).exists():\n",
    "        for z in range(20):\n",
    "            Image.fromarray(image_sample[z]).save(png_fp % z)\n",
    "    return image_sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can insert into the `Volume` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_sample_data()\n",
    "raw_data_shape = raw_data.shape\n",
    "volume_key = dict(volume_id=\"Thy1\", resolution_id=\"990nm\")\n",
    "volume.Volume.insert1(\n",
    "    dict(\n",
    "        **volume_key,\n",
    "        session_id=1,\n",
    "        z_size=raw_data_shape[0],\n",
    "        y_size=raw_data_shape[1],\n",
    "        x_size=raw_data_shape[2],\n",
    "        channel=volume,\n",
    "        **url_key,\n",
    "        volume_data=raw_data,\n",
    "    ),\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can upload our data either from the data stored in the table or a path to images. If this entry is already associated with a `SessionDirectory` entry, we'll look for images in this path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For other optional parameters, see additional docstring info here:\n",
    "# element_volume.export.bossdb.BossDBUpload\n",
    "volume.Volume.upload(volume_key, upload_from=\"table\")\n",
    "# volume.Volume.upload(volume_key, upload_from=\"dir\", data_extension=\"*pattern*.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Volume` and `BossDBURLs` tables offer additional class methods for downloading BossDB data or returning objects for interacting with the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bossdb.BossDBURLs.load_bossdb_info(\n",
    "    collection=\"Kasthuri\",\n",
    "    experiment=\"ac4\",\n",
    "    volume=\"em\",\n",
    "    segmentation=\"neuron\",\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For other optional parameters, see additional docstring info here:\n",
    "# element_volume.readers.bossdb.BossDBInterface.load_data_into_element\n",
    "volume.Volume.download(\n",
    "    \"bossdb://witvliet2020/Dataset_1/em\",\n",
    "    downsampling=3,\n",
    "    slice_key=\"[100:120,1000:1500,1000:1500]\",\n",
    "    save_images=True,\n",
    "    save_ndarray=True,\n",
    "    image_mode=\"P\",\n",
    "    skip_duplicates=True,\n",
    ")\n",
    "data = volume.Volume.return_bossdb_data(\n",
    "    volume_key=dict(volume_id=\"witvliet2020/Dataset_1\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load segmentation data, we can set the `task_mode` to load and add additional pararameters to the `SegmentationParamset` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume.SegmentationParamset.insert_new_params(\n",
    "    segmentation_method=\"bossdb\",\n",
    "    paramset_idx=1,\n",
    "    params=dict(\n",
    "        slice_key=\"[100:120,1000:1500,1000:1500]\",\n",
    "        save_images=True,\n",
    "        save_ndarray=True,\n",
    "        image_mode=\"P\",\n",
    "        skip_duplicates=True,\n",
    "    ),\n",
    ")\n",
    "volume.SegmentationTask.insert1(\n",
    "    dict(\n",
    "        volume_id=\"witvliet2020/Dataset_1\",\n",
    "        resolution_id=0,\n",
    "        task_mode=\"load\",\n",
    "        paramset_idx=1,\n",
    "        **(\n",
    "            bossdb.BossDBURLs.Segmentation & \"collection_experiment LIKE 'wit%'\"\n",
    "        ).fetch1(),\n",
    "    )\n",
    ")\n",
    "volume.Segmentation.populate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [next notebook](./04-Drop.ipynb), we'll touch on how to drop these various schemas for development.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ele')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d00c4ad21a7027bf1726d6ae3a9a6ef39c8838928eca5a3d5f51f3eb68720410"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
